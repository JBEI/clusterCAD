{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem as chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "helper = imp.load_source('helper', './pks/helper.py')\n",
    "domain = imp.load_source('domain', './pks/domain.py')\n",
    "#pks = imp.load_source('pks', './pks/pks.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396\n"
     ]
    }
   ],
   "source": [
    "file_path = './mibig'\n",
    "file_names = glob.glob(os.path.join(file_path, '*.json'))\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '/clusterCAD')\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"clusterCAD.settings\")\n",
    "import django\n",
    "django.setup()\n",
    "import pks.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352 potential type I modular PKS clusters found!\n"
     ]
    }
   ],
   "source": [
    "# This gets all the modular type I PKSs contained in MiBiG\n",
    "t1pks = []\n",
    "for file_name in file_names:\n",
    "    with open(file_name) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    try:        \n",
    "        if len(set(['Modular type I', 'Modular Type I', 'Type I']).intersection(set(json_data['general_params']['Polyketide']['pks_subclass']))) > 0:\n",
    "            accession = json_data['general_params']['loci']['nucl_acc'][0]['Accession']\n",
    "            t1pks.append((file_name.split('/')[-1].split('.')[0], accession))\n",
    "    except KeyError:\n",
    "        pass\n",
    "# Number of clusters found\n",
    "print('%d potential type I modular PKS clusters found!' %(len(t1pks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# antiSMASH output from Tyler\n",
    "antismash_file_path = './mibig/antismash/split_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Proccessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_subunit_modules(sec_met): \n",
    "    '''This function takes as input the the list recorded by feature.qualifiers['sec_met'] for a module in a PKS\n",
    "       cluster. This assumes that feature.type=='CDS' and that feature.qualifiers has the key 'sec_met'.\n",
    "       The function returns a dict corresponding to the modules in the subunit, indexed starting from zero within\n",
    "       the subunit. If the first entry of 'sec_met' is not 'Type: t1pks' then nothing is returned.\n",
    "    '''\n",
    "    # Initialize dict for the subunit\n",
    "    # keys: module number\n",
    "    # values: OrderedDict of domains in module\n",
    "    #         within OrderedDict, key is domain name and value is a length 2 list where the\n",
    "    #         first element is a dictionary {start:, stop:} and the second element is specificity dictionary \n",
    "    subunit = {}\n",
    "    \n",
    "    # This is for the current module (function processes subunit which may have more than one module)\n",
    "    module_index = 0  # key for module\n",
    "    module_domains = [] # list of domains in module\n",
    "    old_module_domains = [] # pre-initialize in case subunit starts with a domain\n",
    "                            # that is expected to end the module\n",
    "    \n",
    "    # This is how domains appear in sec_met:\n",
    "    # ['PKS_AT', 'PKS_KS', 'PKS_KR', 'PKS_DH', 'PKS_ER', 'ACP', 'Thioesterase']\n",
    "    # Iterate over the entries in sec_met, and add them to the module_domains list \n",
    "    for entry in sec_met:    \n",
    "        # Split entry into a list\n",
    "        entrysplit = [item.strip() for item in entry.split(';') if item != '']\n",
    "        # Split part of entry that is expected to describe catalytic domain\n",
    "        domainsplit = entrysplit[0].split()\n",
    "        # This is just different ways of processing the name of the domain depending\n",
    "        # on how the name of the domain is formatted\n",
    "        if ' '.join(domainsplit[:2]) == 'NRPS/PKS Domain:' and len(domainsplit) > 2:\n",
    "            # Note that we want to make sure that there is a leading 'PKS_' before we do our trimming\n",
    "            if domainsplit[2].split('_')[0] == 'PKS':\n",
    "                if domainsplit[2] in ['PKS_Docking_Nterm', 'PKS_Docking_Cterm']:\n",
    "                    domaintype = domainsplit[2]\n",
    "                else:\n",
    "                    # We trim off the leading 'PKS_'\n",
    "                    # Assume 'DH2' and 'DHt' are the same as 'DH' \n",
    "                    domaintype = domainsplit[2].split('_')[-1].replace('DHt', 'DH').replace('DH2', 'DH')\n",
    "            # Special case of 'CAL' domain\n",
    "            elif domainsplit[2] == 'CAL_domain':\n",
    "                domaintype = 'CAL'\n",
    "            else:\n",
    "                domaintype = domainsplit[2]\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        # DEBUG\n",
    "#        print(domaintype)\n",
    "    \n",
    "        # These are the catlytic domains that we want to recognize\n",
    "        if domaintype not in ['KS', 'AT', 'KR', 'DH', 'ER', 'ACP', 'Thioesterase', \n",
    "                              'cMT', 'oMT', 'CAL', 'PCP', \n",
    "                              'Heterocyclization', 'AMP-binding', \n",
    "                              'Condensation_DCL', 'Condensation_LCL',\n",
    "                              'PKS_Docking_Nterm', 'PKS_Docking_Cterm']:\n",
    "            # Break out of for loop and stop looking for additional catalytic domains if \n",
    "            # we encountered a domain that we don't recognize\n",
    "            # we end up excluding any subunit that has a non-recognized catalytic domain\n",
    "            # this is dealt with by checking subunits against those that are expected to be recognized\n",
    "            # as determined by the MiBiG JSON file\n",
    "            break    \n",
    "        # Get the obundaries of the catalytic domain\n",
    "        boundaries = [int(bound) for bound in domainsplit[3].replace('(', '').replace(')', '').replace('.', '').split('-')]\n",
    "        \n",
    "        # Here, we add each domain to a list, which will be converted to an OrderedDict\n",
    "        # based on whether or not the domain is expected to have substrate specificity annotations\n",
    "        if domaintype in ['KS', 'DH', 'ER', 'ACP', 'cMT', 'oMT', 'CAL', 'PCP',\n",
    "                          'Heterocylization', 'AMP-binding', \n",
    "                          'Condensation_DCL', 'Condensation_LCL',\n",
    "                          'PKS_Docking_Nterm', 'PKS_Docking_Cterm']:   # Recall that we trimmed leading 'PKS_'\n",
    "            module_domains.append((domaintype, [{'start': boundaries[0], 'stop': boundaries[1]}]))\n",
    "        # Include substrate and stereospecificity annotations for AT and KR domains respectively\n",
    "        if domaintype in ['AT', 'KR']:   # Recall that we trimmed leading 'PKS_'\n",
    "            notesdict = {}\n",
    "            for note in entrysplit[1:]:\n",
    "                item = note.split(': ')\n",
    "                notesdict[item[0]] = item[1]\n",
    "            module_domains.append((domaintype, [{'start': boundaries[0], 'stop': boundaries[1]}, notesdict]))\n",
    "                \n",
    "        # End of the module has been reached of the domain is 'ACP' or 'PCP\n",
    "        if domaintype in ['ACP', 'PCP']:\n",
    "            domains_present = [d[0] for d in module_domains]\n",
    "            # Make sure every module has an AT, or else it isn't a valid module and we just ignore it\n",
    "            # This means it will be excluded from the subunit, which makes sense since we can't \n",
    "            # really perform a polyketide chain extension without an AT\n",
    "            if 'AT' in domains_present:            \n",
    "                subunit[module_index] = OrderedDict(module_domains)\n",
    "                old_module_domains = module_domains\n",
    "                module_index += 1\n",
    "            else:\n",
    "                old_module_domains = []\n",
    "            module_domains = []\n",
    "        # These domains may come after the ACP or PCP, so if they are encountered, we add\n",
    "        # them to previous module and keep going forward\n",
    "        if domaintype in ['Thioesterase', 'PKS_Docking_Cterm', 'Condensation_LCL']:\n",
    "            # Overwrite previous subunit, or else will have duplicate entries\n",
    "            old_module_domains.append((domaintype, [{'start': boundaries[0], 'stop': boundaries[1]}]))\n",
    "            subunit[module_index - 1] = OrderedDict(old_module_domains)\n",
    "            module_domains = []\n",
    "            \n",
    "    return subunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gene_data(record):\n",
    "    '''Takes as input a record read in from an MiBiG GenBank file using SeqIO.read() and outputs PKS data \n",
    "       from that record. Data will be comprised of PKS subunits and standalone PKS genes.\n",
    "    '''\n",
    "    # Get list to hold information about all genes that are in the record\n",
    "    gene_data = []\n",
    "    \n",
    "    # Only the \"CDS\" features are potentially genes\n",
    "    # Here we get genes that aren't necessarily subunits\n",
    "    for feature in record.features:\n",
    "        # These are the features we are interested in\n",
    "        if feature.type == 'CDS' and 'protein_id' in feature.qualifiers.keys() and 'gene' in feature.qualifiers.keys(): \n",
    "            # This gets the location of the feature\n",
    "            location = feature.location\n",
    "            # Potential information about gene\n",
    "            if 'product' in feature.qualifiers.keys():\n",
    "                description = feature.qualifiers['product'][0]\n",
    "            gene_data.append([feature.qualifiers['protein_id'][0],\n",
    "                              feature.qualifiers['gene'][0],\n",
    "                             ])\n",
    "            # Feature may not be a PKS module and therefore may not have have subunits \n",
    "            # (this will be overwritten if it does have subunits)\n",
    "            subunit_modules = None\n",
    "            # Information if gene is PKS subunit\n",
    "            if 'sec_met' in feature.qualifiers.keys() and len(feature.qualifiers['sec_met']) > 3:\n",
    "                if feature.qualifiers['sec_met'][3] in ['NRPS/PKS subtype: Type I Modular PKS', \n",
    "                                                        'NRPS/PKS subtype: PKS-like protein',\n",
    "                                                        'NRPS/PKS subtype: PKS/NRPS-like protein',\n",
    "                                                        'NRPS/PKS subtype: Hybrid PKS-NRPS']:                    \n",
    "                    # DEBUG\n",
    "#                    print(feature.qualifiers['gene'][0])\n",
    "                    # This gets the subunit information                    \n",
    "                    subunit_modules = process_subunit_modules(feature.qualifiers['sec_met'])\n",
    "#                else:\n",
    "#                    print(feature)\n",
    "            \n",
    "            # More general information\n",
    "            gene_data[-1].extend([description, [location.start.position, location.end.position]])\n",
    "\n",
    "            # Subunit information (if it doesn't have subunit information, assumed to be a standalone enzyme)\n",
    "            if subunit_modules:\n",
    "                gene_data[-1].append(subunit_modules)\n",
    "\n",
    "            # General information about gene\n",
    "            gene_data[-1].append(feature.qualifiers['translation'][0])\n",
    "\n",
    "    return gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_json_module_validity(module_list):\n",
    "    '''Function that makes sure module specified in JSON file is valid,\n",
    "       that is to say, make sure that it contains KS, AT, and ACP or PCP.\n",
    "       AT least as of February 24, 2017, the names of these domains appear\n",
    "       only in the following forms in clusters that are annotated as Type I modular PKSs\n",
    "       ['KS', 'AT', 'T']\n",
    "       ['Ketosynthase', 'Acyltransferase', 'Thiolation (ACP/PCP)']\n",
    "    '''\n",
    "    at_check = len(set(['AT', 'Acyltransferase']).intersection(set(module_list)))\n",
    "    acp_check = len(set(['ACP', 'PCP', 'T', 'Thiolation (ACP/PCP)']).intersection(set(module_list)))\n",
    "\n",
    "    if at_check and acp_check:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def process_cluster(record, cluster_ref, mibig_json):\n",
    "    '''Takes in a record and corresponding MiBiG json file\n",
    "       then returns pks.Cluster object representing the cluster.\n",
    "    '''\n",
    "    # Get information about the gene\n",
    "    gene_data = get_gene_data(record)\n",
    "    if len(gene_data) == 0:\n",
    "        return\n",
    "\n",
    "    # Initalize lists for subunits and standalones\n",
    "    # We make two dictionaries because sometimes the subunit name in the MiBiG JSON files\n",
    "    # is the gene name, e.g. eryA1, and sometimes it is the accession number, e.g. A0000000\n",
    "    unordered_subunits = {}\n",
    "    unordered_subunits_alt = {}\n",
    "    standalones = []\n",
    "     \n",
    "    # Recall that each entry in gene_data is a list\n",
    "    # [protein id, gene, product, [location start, location end], subunit dict (optional), translation]\n",
    "    \n",
    "    #####################\n",
    "    # Basic information #\n",
    "    #####################\n",
    "    \n",
    "    counter = 1\n",
    "    for gene in gene_data:\n",
    "        geneid = gene[0].strip()\n",
    "        genename = gene[1].strip()\n",
    "        genedesc = gene[2].strip()\n",
    "        genestart = gene[3][0]\n",
    "        genestop = gene[3][1]\n",
    "        genetranslation = gene[-1].strip()\n",
    "\n",
    "        # Just use length of gene_data to differentiate between standalones and subunits\n",
    "        if len(gene) == 6:\n",
    "            # We do this to take care of duplicated gene names, as is the case wity tylactone (BGC0000166)\n",
    "            if genename in unordered_subunits_alt.keys():\n",
    "                genename = genename + '_' + str(counter)\n",
    "                counter += 1\n",
    " \n",
    "            # Get subunit data from gene\n",
    "            genesubunitdata = gene[-2]\n",
    "            # Here we use the two dictionary options to save the unordered subunits\n",
    "            # Sometimes MiBiG uses geneid and sometimes it uses genename to reference subunits\n",
    "            unordered_subunits[geneid] = (genename, genedesc, genestart, genestop,\n",
    "                                            genesubunitdata, genetranslation)\n",
    "            unordered_subunits_alt[genename] = (geneid, genedesc, genestart, genestop,\n",
    "                                                genesubunitdata, genetranslation)\n",
    "        else:\n",
    "            # Standalones lack subunit and orphan entries\n",
    "            assert len(gene) == 5, gene\n",
    "            \n",
    "            ########\n",
    "            # CREATE STANDALONE\n",
    "#            pks.models.Standalone(cluster=cluster_ref)\n",
    " #           standalones.append(pks.Standalone(geneid, genename, genedesc, \n",
    " #                                             genestart, genestop, genetranslation))\n",
    "        \n",
    "    #########################################\n",
    "    # JSON file has cyclization information #\n",
    "    #########################################\n",
    "\n",
    "    # Get ordered version of subunits from corresponding JSON file\n",
    "    with open(mibig_json) as json_file:\n",
    "        mibig_data = json.load(json_file)\n",
    "    \n",
    "    # Get PKS cyclization information\n",
    "    # this will be either 'Cyclic' or 'Linear'\n",
    "    try:\n",
    "        lin_cycl_pk = mibig_data['general_params']['Polyketide']['lin_cycl_pk']\n",
    "        if lin_cycl_pk == 'Cyclic':\n",
    "            cyclize = True\n",
    "        elif lin_cycl_pk == 'Linear':\n",
    "            cyclize = False\n",
    "        else:\n",
    "            raise Exception(\"lin_cycl_pk expected to be 'Cyclic' or 'Linear'.\")\n",
    "    except KeyError:\n",
    "        cyclize = False\n",
    "            \n",
    "    #####################################\n",
    "    # JSON file has subunit information #\n",
    "    #####################################\n",
    "        \n",
    "    # Note that all gene data has now been processed, want to reprocess to get right ordering \n",
    "    # We strip out subunits that have invalid modules\n",
    "    try:\n",
    "        ordered_subunits = []\n",
    "        for subunit in mibig_data['general_params']['Polyketide']['mod_pks_genes']:\n",
    "            subunit_name = re.sub(r'\\s+', '', subunit['mod_pks_gene'])\n",
    "            subunit_modules = subunit['pks_module']\n",
    "\n",
    "            valid_subunit = True\n",
    "            # This checks if the module is valid\n",
    "            for module in subunit_modules:\n",
    "                # Just for debugging\n",
    "    #            print(module['pks_domains'])\n",
    "                if not check_json_module_validity(module['pks_domains']):\n",
    "                    valid_subunit = False\n",
    "            if valid_subunit:\n",
    "                ordered_subunits.extend(subunit_name.split(','))\n",
    "            else:\n",
    "                # Loop is broken once first invalid subunit is encountered\n",
    "                break\n",
    "        # If no valid subunits, then just return\n",
    "        if len(ordered_subunits) == 0:\n",
    "            print('\\tNo valid subunits!')\n",
    "            for subunit in mibig_data['general_params']['Polyketide']['mod_pks_genes']:\n",
    "                subunit_name = re.sub(r'\\s+', '', subunit['mod_pks_gene'])\n",
    "                subunit_modules = subunit['pks_module']\n",
    "                for module in subunit_modules:\n",
    "                    print(module['pks_domains'])\n",
    "            return\n",
    "        # This makes sure the subunit accession naming is consistent\n",
    "        # The purpose of these two 'if' statements is because there may be cases in the MiBiG JSON file\n",
    "        # where the name of the gene is for example, 'eryA1, A000000' and we want to keep consistant naming\n",
    "        if len(ordered_subunits[0]) >= 8:\n",
    "            ordered_subunits = [entry for entry in ordered_subunits if len(entry) >= 8]\n",
    "        if len(ordered_subunits) > 1:\n",
    "            if len(ordered_subunits[1]) >= 8:\n",
    "                ordered_subunits = [entry for entry in ordered_subunits if len(entry) >= 8]\n",
    "        # This is because sometimes the accession number under which the gene is recorded sometimes\n",
    "        # has a version number, and sometimes does not\n",
    "        if len(ordered_subunits[0].split('.')) == 1 and len(ordered_subunits[0]) == 8:\n",
    "            ordered_subunits = [entry + '.1' for entry in ordered_subunits]\n",
    "\n",
    "        # Check if subunit is in either dictionary\n",
    "        for isubunit,subunit in enumerate(ordered_subunits):\n",
    "            if subunit not in set(list(unordered_subunits.keys()) + list(unordered_subunits_alt.keys())):\n",
    "                print('Missing subunit: \"%s\"' %(subunit))\n",
    "                for gene in mibig_data['general_params']['Polyketide']['mod_pks_genes']:\n",
    "                    if gene['mod_pks_gene'] == subunit:\n",
    "                        module = gene['pks_module']\n",
    "                        for entry in module:\n",
    "                            print(entry['pks_domains'])\n",
    "                print(unordered_subunits.keys())\n",
    "                return\n",
    "    #    print([gene_ref for gene_ref in mibig_data['general_params']['Polyketide']['mod_pks_genes']])\n",
    "\n",
    "        # Determine whether to use standard or alternative dict\n",
    "        if len(ordered_subunits[0]) >= 8:\n",
    "            alt = False\n",
    "        else:\n",
    "            alt = True\n",
    "    \n",
    "    # Just use unordered gene order if the gene ordering is not already in the JSON file \n",
    "    except Exception:\n",
    "        ordered_subunits = list(unordered_subunits_alt.keys())\n",
    "        ordered_subunits.sort()\n",
    "        alt = True\n",
    "\n",
    "    ####################################\n",
    "    # This does the subunit reordering #\n",
    "    ####################################\n",
    "    for subunit_key in ordered_subunits:\n",
    "        # subunit data has form (id, description, start, stop, module dict, sequence)\n",
    "        if not alt:\n",
    "            subunitdata = unordered_subunits[subunit_key]\n",
    "        else:\n",
    "            subunitdata = unordered_subunits_alt[subunit_key]\n",
    "     \n",
    "        if not alt:\n",
    "            # subunit = id\n",
    "            # subunit[0] = name\n",
    "            # id, name, description, start, stop, sequence\n",
    "            subunit = pks.models.Subunit(cluster=cluster_ref,\n",
    "                                         genbankAccession=subunit_key,\n",
    "                                         name=subunitdata[0],\n",
    "                                         start=subunitdata[2],\n",
    "                                         stop=subunitdata[3],\n",
    "                                         sequence=subunitdata[-1])\n",
    "            subunit.save()\n",
    "            # subunits.append(pks.Subunit(subunit, subunitdata[0], subunitdata[1],\n",
    "            #                            subunitdata[2], subunitdata[3], subunitdata[-1],\n",
    "            #                            modules))\n",
    "        else:\n",
    "            # subunit = name\n",
    "            # subunit[0] = id\n",
    "            subunit = pks.models.Subunit(cluster=cluster_ref,\n",
    "                                         genbankAccession=subunitdata[0],\n",
    "                                         name=subunit_key,\n",
    "                                         start=subunitdata[2],\n",
    "                                         stop=subunitdata[3],\n",
    "                                         sequence=subunitdata[-1])\n",
    "            subunit.save()\n",
    "                \n",
    "                # subunits.append(pks.Subunit(subunitdata[0], subunit, subunitdata[1],\n",
    "                #                            subunitdata[2], subunitdata[3], subunitdata[-1],\n",
    "                #                            modules))\n",
    "        \n",
    "        # This is the modules for the subunit\n",
    "        moduledata = subunitdata[-2]\n",
    "        \n",
    "        # We do this so we can lump in the loading didomain and TE on the first and last modules respectively\n",
    "        modulekeys = list(moduledata.keys())\n",
    "        imodule = 0\n",
    "        modules_seen = 0\n",
    "        while imodule < len(modulekeys):\n",
    "            # Get info\n",
    "            keys = list(moduledata[modulekeys[imodule]].keys())\n",
    "            values = moduledata[modulekeys[imodule]].values()\n",
    "            # Process info according to loading or not\n",
    "            if modules_seen == 0:\n",
    "                loading = True                \n",
    "                # Don't name KSQ and ATL separate after all\n",
    "#                moduledict =  OrderedDict([(k.replace('KS', 'KS').replace('AT', 'AT'), v) \\\n",
    "#                                          if k in ['KS','AT'] \\\n",
    "#                                          else (k,v) \\\n",
    "#                                          for k,v in zip(keys,values)])\n",
    "                moduledict =  OrderedDict([(k,v) for k,v in zip(keys,values)])\n",
    "            else: \n",
    "                loading = False\n",
    "                moduledict = OrderedDict([(k,v) for k,v in zip(keys,values)])\n",
    "            # Determine whether module is terminal or not\n",
    "            if 'Thioesterase' in list(moduledata[modulekeys[imodule]].keys()):\n",
    "                terminal = True\n",
    "            else:\n",
    "                terminal = False\n",
    "            imodule += 1\n",
    "            modules_seen += 1\n",
    "            try:\n",
    "                # This is to make sure we don't add subunits with invalid modules\n",
    "                # The check for errors here is to compare agains the predicted chemcial structure\n",
    "                domains_present = moduledict.keys()\n",
    "                if 'ACP' in domains_present or 'PCP' in domains_present:\n",
    "                    if 'AT' in domains_present or 'ATL' in domains_present:\n",
    "                        module = pks.models.Module(subunit=subunit, loading=loading, terminal=terminal)\n",
    "                        module.save()\n",
    "                        module.buildDomains(moduledict, cyclic=cyclize)\n",
    "                        \n",
    "                        # modules.append(pks.Module(moduledict, loading=loading, terminal=terminal))\n",
    "            except AssertionError as e:\n",
    "                print(moduledict)\n",
    "                print(type(e).__name__, e.args, subunit + ' ' + subunitdata[1])\n",
    "                raise Exception(type(e).__name__, e.args, subunit + ' ' + subunitdata[1])\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Testing specific entries\n",
    "entry = ('BGC0000055', 'U78289')  # tylactone\n",
    "#entry = ('BGC0000033', 'AF497482') # calicheamicin\n",
    "\n",
    "with open(os.path.join(file_path, entry[0] + '.json')) as json_file:\n",
    "    mibig_data = json.load(json_file)\n",
    "#pprint(test_data.keys())\n",
    "#pprint(test_data['general_params'].keys())\n",
    "#pprint(test_data['general_params'])\n",
    "#pprint([gene_ref['mod_pks_gene'] for gene_ref in test_data['general_params']['Polyketide']['mod_pks_genes']])\n",
    "record = SeqIO.read(os.path.join(antismash_file_path, entry[0] + '.embl'), \"embl\")\n",
    "\n",
    "# antismash_data = get_gene_data(record)\n",
    "# for subunit in antismash_data:\n",
    "#     if len(subunit) == 6:\n",
    "#         print(subunit)\n",
    "\n",
    "# TYLER: CLUSTER CREATION\n",
    "[cluster.delete() for cluster in pks.models.Cluster.objects.all()]\n",
    "cluster_ref = pks.models.Cluster(\n",
    "    genbankAccession = record.annotations['comment'].split()[-1].strip().strip('.'), \\\n",
    "    mibigAccession = record.id, \\\n",
    "    description= record.description, \\\n",
    "    sequence= record.seq)\n",
    "cluster_ref.save()\n",
    "\n",
    "process_cluster(record, cluster_ref, os.path.join(file_path, entry[0] + '.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('BGC0000001', 'JF752342')\n",
      "['Abyssomicin C', 'Atrop-abyssomicin C']\n",
      "1: ('BGC0000002', 'CP007155')\n",
      "['aculeximycin']\n",
      "2: ('BGC0000003', 'AB179766')\n",
      "['AF-toxin']\n",
      "3: ('BGC0000004', 'AB196490')\n",
      "['aflatoxin']\n",
      "4: ('BGC0000005', 'AF452809')\n",
      "['aflatoxin']\n",
      "5: ('BGC0000006', 'AY510451')\n",
      "['aflatoxin']\n",
      "6: ('BGC0000007', 'AY510452')\n",
      "['aflatoxin']\n",
      "7: ('BGC0000008', 'AY510453')\n",
      "['aflatoxin']\n",
      "8: ('BGC0000009', 'AY510454')\n",
      "['aflatoxin']\n",
      "9: ('BGC0000010', 'AY510455')\n",
      "['aflatoxin']\n",
      "10: ('BGC0000011', 'AY092402')\n",
      "['aflatoxin', 'sterigmatocystin']\n",
      "11: ('BGC0000012', 'AB120221')\n",
      "['alternapyrone']\n",
      "12: ('BGC0000013', 'BN001304')\n",
      "['alternariol']\n",
      "13: ('BGC0000014', 'DQ897667')\n",
      "['ambruticin']\n",
      "14: ('BGC0000015', 'AF357202')\n",
      "['amphotericin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/Bio/GenBank/__init__.py:1218: BiopythonParserWarning: Expected sequence length 113193, found 135074 (BGC0000015.1).\n",
      "  BiopythonParserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15: ('BGC0000017', 'FJ477836')\n",
      "['Anatoxin-a', 'Homoanatoxin-a']\n",
      "16: ('BGC0000018', 'EU220288')\n",
      "['angolamycin']\n",
      "17: ('BGC0000019', 'EU232693')\n",
      "['angolamycin']\n",
      "18: ('BGC0000020', 'AF453501')\n",
      "['ansamitocin']\n",
      "19: ('BGC0000021', 'JF819834')\n",
      "['apoptolidin']\n",
      "20: ('BGC0000022', 'AACD01000015')\n",
      "['asperfuranone']\n",
      "21: ('BGC0000023', 'AM850130')\n",
      "['Aurafuron A']\n"
     ]
    }
   ],
   "source": [
    "[cluster.delete() for cluster in pks.models.Cluster.objects.all()]\n",
    "\n",
    "# Iterate over list of type I modular PKSs\n",
    "for i in range(len(t1pks)):\n",
    "    print('%d: %s' %(i, t1pks[i]))\n",
    "    entry = t1pks[i]\n",
    "\n",
    "     # This prints the accession number and product compound of the cluster\n",
    "    with open(os.path.join(file_path, entry[0] + '.json')) as json_file:\n",
    "        mibig_data = json.load(json_file)\n",
    "        pprint([compound['compound'] for compound in mibig_data['general_params']['compounds']])\n",
    "\n",
    "    # Read in cluster data\n",
    "    record = SeqIO.read(os.path.join(antismash_file_path, entry[0] + '.embl'), \"embl\")    \n",
    "\n",
    "    try:\n",
    "        cluster_ref = pks.models.Cluster(\n",
    "            genbankAccession = record.annotations['comment'].split()[-1].strip().strip('.'), \\\n",
    "            mibigAccession = record.id, \\\n",
    "            description= record.description, \\\n",
    "            sequence= record.seq)\n",
    "        cluster_ref.save()\n",
    "\n",
    "        process_cluster(record, cluster_ref, os.path.join(file_path, entry[0] + '.json'))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# delete clusters with no modules\n",
    "for cluster in pks.models.Cluster.objects.all():\n",
    "    for subunit in cluster.subunits():\n",
    "        if len(subunit.modules()) == 0:\n",
    "            subunit.delete()\n",
    "    if len(cluster.subunits()) == 0:\n",
    "        cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# delete clusters with no computable product\n",
    "for cluster in pks.models.Cluster.objects.all():\n",
    "    try:\n",
    "        cluster.computeProduct()\n",
    "    except:\n",
    "        cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
